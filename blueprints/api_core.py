#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒAPI Blueprint - å¤„ç†ç³»ç»Ÿã€é…ç½®ã€èµ„æºã€æ—¥å¿—å’Œç»´æŠ¤ç›¸å…³çš„API
"""

import os
import json
import math
import logging
import time
import pprint
from datetime import datetime, timezone
from flask import Blueprint, jsonify, request, current_app, Response
from sqlalchemy import func, or_, and_

from models import db, Resource, Category
from configuration import Config
from cache_manager import cache_manager, CacheKeys
from utils.logging_handler import logs_buffer
from utils.api_response import (
    success_response,
    error_response,
    ErrorCode,
    missing_parameter_response,
    invalid_parameter_response,
    not_found_response,
    operation_failed_response,
    log_api_call,
    log_error_with_traceback
)
from utils.validators import (
    PaginationValidator,
    DateValidator,
    StringValidator,
    RequestParams
)
from services.resource_service import UnifiedService

api_core_bp = Blueprint('api_core', __name__, url_prefix='/api')

# æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆä» current_app.config åŠ¨æ€è·å–ï¼‰
logger = logging.getLogger(__name__)

# æ—¥å¿—ç‰ˆæœ¬å·ï¼ˆç”¨äºé˜²æ­¢ç¼“å­˜ï¼‰
_log_version = 0


# ==================== ç³»ç»ŸAPI ====================

@api_core_bp.route('/stats')
def api_stats():
    """è·å–ç»Ÿè®¡æ•°æ® - ä¼˜åŒ–ç¼“å­˜ç­–ç•¥"""
    # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå»¶é•¿ç¼“å­˜æ—¶é—´åˆ°15åˆ†é’Ÿï¼‰
    cache_key = CacheKeys.STATS
    cached_stats = cache_manager.get(cache_key)
    if cached_stats:
        return jsonify(cached_stats)

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    stats = Resource.get_statistics()

    # ç¼“å­˜ç»“æœï¼ˆ15åˆ†é’Ÿ = 900ç§’ï¼‰
    cache_manager.set(cache_key, stats, ttl=900)

    return jsonify(stats)


@api_core_bp.route('/version')
def api_version():
    """è·å–ç³»ç»Ÿç‰ˆæœ¬"""
    return jsonify({'version': Config.VERSION})


# ==================== é…ç½®API ====================

@api_core_bp.route('/config')
def api_config():
    """è·å–é…ç½®çŠ¶æ€ï¼ˆä¸è¿”å›æ•æ„Ÿä¿¡æ¯ï¼‰"""
    start_time = time.time()

    try:
        config = current_app.config

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/config',
            params={},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        response_data = {
            'tg_bot_token_set': bool(config.get('TG_BOT_TOKEN')),
            'proxy_set': bool(config.get('PROXY')),
            'bypass_url_set': bool(config.get('BYPASS_URL')),
            'flare_solverr_url_set': bool(config.get('FLARE_SOLVERR_URL'))
        }

        response = jsonify(response_data)
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        return success_response(
            data=response_data,
            message='è·å–é…ç½®çŠ¶æ€æˆåŠŸ'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/config'},
            message='è·å–é…ç½®çŠ¶æ€å¤±è´¥'
        )

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/config',
            params={},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='è·å–é…ç½®çŠ¶æ€å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/config/set', methods=['POST'])
def api_config_set():
    """è®¾ç½®ç³»ç»Ÿé…ç½®API - æ”¯æŒæŒä¹…åŒ–é…ç½®"""
    start_time = time.time()
    try:
        from configuration import config_manager

        data = request.get_json(silent=True) or {}
        keys = [
            'TG_BOT_TOKEN', 'TG_NOTIFY_CHAT_ID', 'PROXY', 'BYPASS_URL',
            'FLARE_SOLVERR_URL', 'LOG_LEVEL', 'LOG_BUFFER_SIZE', 'SAFE_MODE',
            'CRAWLER_MODE', 'CRAWLER_MAX_CONCURRENCY', 'CRAWLER_THREAD_COUNT',
            'CRAWLER_ASYNC_DELAY_MIN', 'CRAWLER_ASYNC_DELAY_MAX',
            'CRAWLER_SYNC_DELAY_MIN', 'CRAWLER_SYNC_DELAY_MAX',
            'HEARTBEAT_INTERVAL', 'GLOBAL_ERROR_THRESHOLD',
            'AUTO_CRAWL_ENABLED', 'AUTO_CRAWL_TIME'
        ]

        # æ›´æ–°é…ç½®
        config_updates = {}
        for k in keys:
            if k in data:
                val = data.get(k)
                # å¯¹äºSAFE_MODEï¼Œå­˜å‚¨ä¸ºå¸ƒå°”å€¼
                if k == 'SAFE_MODE':
                    config_updates[k] = bool(val)  # ç›´æ¥è½¬æ¢ä¸ºå¸ƒå°”å€¼
                # å¯¹äºAUTO_CRAWL_ENABLEDï¼Œä¹Ÿå­˜å‚¨ä¸ºå¸ƒå°”å€¼
                elif k == 'AUTO_CRAWL_ENABLED':
                    config_updates[k] = bool(val)
                # å¯¹äºCRAWLER_MODEï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„å­—ç¬¦ä¸²å€¼
                elif k == 'CRAWLER_MODE':
                    # ç¡®ä¿å€¼æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä¸”æ˜¯æœ‰æ•ˆçš„æ¨¡å¼
                    str_val = str(val) if val else 'async'
                    if str_val.lower() in ('async', 'thread', 'sync'):
                        config_updates[k] = str_val.lower()
                    else:
                        config_updates[k] = 'async'  # æ— æ•ˆå€¼ä½¿ç”¨é»˜è®¤å€¼
                # æ•´æ•°ç±»å‹å¤„ç†
                elif k in ('LOG_BUFFER_SIZE', 'CRAWLER_MAX_CONCURRENCY', 'CRAWLER_THREAD_COUNT', 'HEARTBEAT_INTERVAL'):
                    try:
                        num_val = int(val)
                        if k == 'LOG_BUFFER_SIZE':
                            config_updates[k] = max(1000, min(num_val, 100000))
                        elif k == 'CRAWLER_MAX_CONCURRENCY':
                            config_updates[k] = max(1, min(num_val, 100))
                        elif k == 'CRAWLER_THREAD_COUNT':
                            config_updates[k] = max(1, min(num_val, 50))
                        elif k == 'HEARTBEAT_INTERVAL':
                            config_updates[k] = max(10, min(num_val, 600))  # é™åˆ¶åœ¨10-600ç§’
                    except (ValueError, TypeError):
                        pass # ä¿æŒé»˜è®¤æˆ–è·³è¿‡æ— æ•ˆå€¼
                # æµ®ç‚¹æ•°å»¶è¿Ÿå¤„ç†
                elif k.endswith('_DELAY_MIN') or k.endswith('_DELAY_MAX'):
                    try:
                        config_updates[k] = float(val)
                    except (ValueError, TypeError):
                        pass
                else:
                    config_updates[k] = val or ''

        # æ‰¹é‡æ›´æ–°é…ç½®ï¼ˆä¼šåŒæ—¶æ›´æ–°ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶ï¼‰
        if config_updates:
            success = config_manager.update(config_updates, section='app')
            if not success:
                logger.error(f"âœ— [CONFIG] é…ç½®ä¿å­˜åˆ°æ–‡ä»¶å¤±è´¥")

                log_api_call(
                    logger,
                    method='POST',
                    endpoint='/api/config/set',
                    params={'config_updates': config_updates},
                    status='error',
                    response_code=500,
                    duration_ms=(time.time() - start_time) * 1000,
                    error='é…ç½®ä¿å­˜å¤±è´¥'
                )

                return operation_failed_response('é…ç½®ä¿å­˜å¤±è´¥')
            else:
                logger.info(f"âœ“ [CONFIG] é…ç½®å·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶")

        # å¦‚æœä¿®æ”¹äº†æ—¥å¿—ç­‰çº§ï¼Œç«‹å³åº”ç”¨
        if 'LOG_LEVEL' in data:
            config_manager.apply_log_level()
            logger.info(f"âœ“ [CONFIG] æ—¥å¿—ç­‰çº§å·²æ›´æ–°: {data['LOG_LEVEL']}")
            logger.debug("è¿™æ˜¯ä¸€æ¡DEBUGçº§åˆ«çš„æµ‹è¯•æ—¥å¿— - å¦‚æœä½ çœ‹åˆ°è¿™æ¡æ—¥å¿—è¯´æ˜DEBUGç­‰çº§å·²ç”Ÿæ•ˆ")

        # å¦‚æœä¿®æ”¹äº†æ—¥å¿—ç¼“å†²åŒºå¤§å°ï¼Œæç¤ºéœ€è¦é‡å¯
        if 'LOG_BUFFER_SIZE' in data:
            logger.info(f"âœ“ [CONFIG] æ—¥å¿—ç¼“å†²åŒºå¤§å°å·²æ›´æ–°: {data['LOG_BUFFER_SIZE']} æ¡")
            logger.info(f"ğŸ’¡ [CONFIG] æ—¥å¿—ç¼“å†²åŒºå¤§å°å°†åœ¨ä¸‹æ¬¡é‡å¯åç”Ÿæ•ˆ")

        # å¦‚æœä¿®æ”¹äº†çˆ¬è™«æ¨¡å¼ï¼Œè®°å½•æ—¥å¿—
        if 'CRAWLER_MODE' in data:
            mode = data['CRAWLER_MODE']
            mode_name = {
                'async': 'å¼‚æ­¥æ¨¡å¼ (é«˜æ€§èƒ½)',
                'thread': 'å¤šçº¿ç¨‹æ¨¡å¼',
                'sync': 'ä¸²è¡Œæ¨¡å¼'
            }.get(mode, mode)
            logger.info(f"âœ“ [CONFIG] çˆ¬è™«æ¨¡å¼å·²æ›´æ–°: {mode_name}")
            logger.info(f"ğŸ’¡ [CONFIG] ä¸‹æ¬¡çˆ¬å–ä»»åŠ¡å°†ä½¿ç”¨ {mode} æ¨¡å¼")
            logger.info(f"ğŸ“ [CONFIG] é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼Œé‡å¯åä¾ç„¶ç”Ÿæ•ˆ")
        
        # å¦‚æœä¿®æ”¹äº†å®šæ—¶çˆ¬å–é…ç½®ï¼Œç«‹å³æ›´æ–°ä»»åŠ¡ç®¡ç†å™¨
        if 'AUTO_CRAWL_ENABLED' in data or 'AUTO_CRAWL_TIME' in data:
            try:
                # ä»»åŠ¡ç®¡ç†å™¨å·²åœç”¨ï¼Œä»…è®°å½•æ—¥å¿—
                auto_enabled = config_manager.get('AUTO_CRAWL_ENABLED', False)
                auto_time = config_manager.get('AUTO_CRAWL_TIME', '03:00')
                logger.info(f"âœ“ [CONFIG] æ¯æ—¥å®šæ—¶çˆ¬å–é…ç½®å·²æ›´æ–°: {'å¼€å¯' if auto_enabled else 'å…³é—­'} @ {auto_time}")
                logger.info(f"ğŸ’¡ [CONFIG] æ³¨æ„: ä»»åŠ¡ç®¡ç†å™¨å·²åœç”¨ï¼Œå®šæ—¶çˆ¬å–åŠŸèƒ½éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼å®ç°")
            except Exception as te:
                logger.error(f"âœ— [CONFIG] æ›´æ–°å®šæ—¶ä»»åŠ¡é…ç½®å¤±è´¥: {te}")

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/config/set',
            params={'keys': list(data.keys()) if data else []},
            status='success',
            response_code=200,
            duration_ms=(time.time() - start_time) * 1000
        )

        return success_response(
            message='é…ç½®æ›´æ–°æˆåŠŸ'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/config/set'},
            message='é…ç½®æ›´æ–°å¤±è´¥'
        )

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/config/set',
            params={},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='é…ç½®æ›´æ–°å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/crawl/stop', methods=['POST'])
def api_crawl_stop():
    """åœæ­¢çˆ¬è™«ä»»åŠ¡"""
    start_time = time.time()

    try:
        from scheduler.utils import stop_crawling_task

        # å¼ºåˆ¶åœæ­¢å‚æ•°
        force = request.json.get('force', False) if request.is_json else False

        success, message = stop_crawling_task(force=force)

        duration_ms = (time.time() - start_time) * 1000

        if success:
            logger.info(f"âœ… [API] åœæ­¢çˆ¬è™«æˆåŠŸ: {message}")

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/crawl/stop',
                params={'force': force},
                status='success',
                response_code=200,
                duration_ms=duration_ms
            )

            return success_response(
                message=message,
                force_used=force
            )
        else:
            logger.warning(f"âš ï¸ [API] åœæ­¢çˆ¬è™«å¤±è´¥: {message}")

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/crawl/stop',
                params={'force': force},
                status='error',
                response_code=400,
                duration_ms=duration_ms,
                error=message
            )

            return error_response(
                code=ErrorCode.BUSINESS_ERROR,
                message=message
            )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/crawl/stop'},
            message='åœæ­¢çˆ¬è™«å¼‚å¸¸'
        )

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/crawl/stop',
            params={'force': request.json.get('force') if request.is_json else None},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='åœæ­¢çˆ¬è™«å¼‚å¸¸',
            details=str(e)
        )


@api_core_bp.route('/crawl/pause', methods=['POST'])
def api_crawl_pause():
    """æš‚åœçˆ¬è™«ä»»åŠ¡"""
    start_time = time.time()

    try:
        from scheduler.utils import pause_crawling_task
        success, message = pause_crawling_task()
        if success:
            logger.info(f"âœ… [API] æš‚åœçˆ¬è™«æˆåŠŸ: {message}")

            duration_ms = (time.time() - start_time) * 1000

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/crawl/pause',
                params={},
                status='success',
                response_code=200,
                duration_ms=duration_ms
            )

            return success_response(
                message=message
            )
        else:
            duration_ms = (time.time() - start_time) * 1000

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/crawl/pause',
                params={},
                status='error',
                response_code=400,
                duration_ms=duration_ms,
                error=message
            )

            return error_response(
                code=ErrorCode.BUSINESS_ERROR,
                message=message
            )
    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/crawl/pause'},
            message='æš‚åœçˆ¬è™«å¼‚å¸¸'
        )

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/crawl/pause',
            params={},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='æš‚åœçˆ¬è™«å¼‚å¸¸',
            details=str(e)
        )


@api_core_bp.route('/crawl/resume', methods=['POST'])
def api_crawl_resume():
    """æ¢å¤çˆ¬è™«ä»»åŠ¡"""
    start_time = time.time()

    try:
        from scheduler.utils import resume_crawling_task
        success, message = resume_crawling_task()
        if success:
            logger.info(f"âœ… [API] æ¢å¤çˆ¬è™«æˆåŠŸ: {message}")

            duration_ms = (time.time() - start_time) * 1000

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/crawl/resume',
                params={},
                status='success',
                response_code=200,
                duration_ms=duration_ms
            )

            return success_response(
                message=message
            )
        else:
            duration_ms = (time.time() - start_time) * 1000

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/crawl/resume',
                params={},
                status='error',
                response_code=400,
                duration_ms=duration_ms,
                error=message
            )

            return error_response(
                code=ErrorCode.BUSINESS_ERROR,
                message=message
            )
    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/crawl/resume'},
            message='æ¢å¤çˆ¬è™«å¼‚å¸¸'
        )

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/crawl/resume',
            params={},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='æ¢å¤çˆ¬è™«å¼‚å¸¸',
            details=str(e)
        )


@api_core_bp.route('/config/values')
def api_config_values():
    """è¿”å›å¯å®‰å…¨å±•ç¤ºçš„é…ç½®å€¼ï¼Œç”¨äºå‰ç«¯è¡¨å•é¢„å¡«"""
    try:
        from configuration import config_manager

        # è·å–å®‰å…¨æ¨¡å¼è®¾ç½®ï¼ˆå¤„ç†å¤šç§ç±»å‹ï¼‰
        safe_mode_val = config_manager.get('SAFE_MODE', False)
        # å…¼å®¹å¤„ç†ï¼šå¯èƒ½æ˜¯å¸ƒå°”å€¼ã€å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
        if isinstance(safe_mode_val, bool):
            safe_mode = safe_mode_val
        elif isinstance(safe_mode_val, str):
            safe_mode = safe_mode_val.lower() in ('true', '1', 'yes')
        else:
            safe_mode = bool(safe_mode_val)

        response = jsonify({
            'PROXY': config_manager.get('PROXY', ''),
            'BYPASS_URL': config_manager.get('BYPASS_URL', ''),
            'FLARE_SOLVERR_URL': config_manager.get('FLARE_SOLVERR_URL', ''),
            'TG_BOT_TOKEN': '***å·²è®¾ç½®***' if config_manager.get('TG_BOT_TOKEN', '') else '',
            'TG_BOT_TOKEN_SET': bool(config_manager.get('TG_BOT_TOKEN', '')),
            'TG_NOTIFY_CHAT_ID': config_manager.get('TG_NOTIFY_CHAT_ID', ''),
            'LOG_LEVEL': config_manager.get('LOG_LEVEL', 'INFO'),
            'LOG_BUFFER_SIZE': config_manager.get('LOG_BUFFER_SIZE', 10000),
            'SAFE_MODE': safe_mode,
            'CRAWLER_MODE': config_manager.get('CRAWLER_MODE', 'async'),
            'CRAWLER_MAX_CONCURRENCY': config_manager.get('CRAWLER_MAX_CONCURRENCY', 20),
            'CRAWLER_THREAD_COUNT': config_manager.get('CRAWLER_THREAD_COUNT', 10),
            'CRAWLER_ASYNC_DELAY_MIN': config_manager.get('CRAWLER_ASYNC_DELAY_MIN', 0.5),
            'CRAWLER_ASYNC_DELAY_MAX': config_manager.get('CRAWLER_ASYNC_DELAY_MAX', 1.5),
            'CRAWLER_SYNC_DELAY_MIN': config_manager.get('CRAWLER_SYNC_DELAY_MIN', 0.3),
            'CRAWLER_SYNC_DELAY_MAX': config_manager.get('CRAWLER_SYNC_DELAY_MAX', 0.8),
            'HEARTBEAT_INTERVAL': config_manager.get('HEARTBEAT_INTERVAL', 60),
            'GLOBAL_ERROR_THRESHOLD': config_manager.get('GLOBAL_ERROR_THRESHOLD', 300),
            'AUTO_CRAWL_ENABLED': config_manager.get('AUTO_CRAWL_ENABLED', False),
            'AUTO_CRAWL_TIME': config_manager.get('AUTO_CRAWL_TIME', '03:00'),
            # å¢åŠ çˆ¬è™«ç‰¹å®šé…ç½®ï¼Œä¾¿äºå¤šç«¯åŒæ­¥
            'CRAWL_FORUMS': config_manager.get_crawl_config('selected_forums') or [],
            'CRAWL_DATE_MODE': config_manager.get_crawl_config('date_mode') or 'all',
            'CRAWL_PAGE_MODE': config_manager.get_crawl_config('page_mode') or 'fixed',
            'CRAWL_MAX_PAGES': config_manager.get_crawl_config('max_pages') or 3,
            'CRAWL_SMART_LIMIT': config_manager.get_crawl_config('smart_limit') or 500
        })
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        return response
    except Exception as e:
        logger.error(f"âœ— [CONFIG] è·å–é…ç½®å€¼å¤±è´¥: {e}")

        safe_mode_raw = current_app.config.get('SAFE_MODE')
        if safe_mode_raw is None:
            safe_mode_raw = os.environ.get('SAFE_MODE', False)
        if isinstance(safe_mode_raw, bool):
            safe_mode = safe_mode_raw
        elif isinstance(safe_mode_raw, str):
            safe_mode = safe_mode_raw.lower() in ('true', '1', 'yes')
        else:
            safe_mode = bool(safe_mode_raw)

        response = jsonify({
            'PROXY': current_app.config.get('PROXY') or os.environ.get('PROXY') or '',
            'BYPASS_URL': current_app.config.get('BYPASS_URL') or os.environ.get('BYPASS_URL') or '',
            'FLARE_SOLVERR_URL': current_app.config.get('FLARE_SOLVERR_URL') or os.environ.get('FLARE_SOLVERR_URL') or '',
            'TG_BOT_TOKEN': '***å·²è®¾ç½®***' if (current_app.config.get('TG_BOT_TOKEN') or os.environ.get('TG_BOT_TOKEN')) else '',
            'TG_BOT_TOKEN_SET': bool(current_app.config.get('TG_BOT_TOKEN') or os.environ.get('TG_BOT_TOKEN')),
            'TG_NOTIFY_CHAT_ID': current_app.config.get('TG_NOTIFY_CHAT_ID') or os.environ.get('TG_NOTIFY_CHAT_ID') or '',
            'LOG_LEVEL': current_app.config.get('LOG_LEVEL') or os.environ.get('LOG_LEVEL') or 'INFO',
            'LOG_BUFFER_SIZE': current_app.config.get('LOG_BUFFER_SIZE') or int(os.environ.get('LOG_BUFFER_SIZE', 10000)),
            'SAFE_MODE': safe_mode,
            'CRAWLER_MODE': current_app.config.get('CRAWLER_MODE') or os.environ.get('CRAWLER_MODE') or 'async',
            'CRAWLER_MAX_CONCURRENCY': current_app.config.get('CRAWLER_MAX_CONCURRENCY') or int(os.environ.get('CRAWLER_MAX_CONCURRENCY', 20)),
            'CRAWLER_THREAD_COUNT': current_app.config.get('CRAWLER_THREAD_COUNT') or int(os.environ.get('CRAWLER_THREAD_COUNT', 10)),
            'CRAWLER_ASYNC_DELAY_MIN': current_app.config.get('CRAWLER_ASYNC_DELAY_MIN') or float(os.environ.get('CRAWLER_ASYNC_DELAY_MIN', 0.5)),
            'CRAWLER_ASYNC_DELAY_MAX': current_app.config.get('CRAWLER_ASYNC_DELAY_MAX') or float(os.environ.get('CRAWLER_ASYNC_DELAY_MAX', 1.5)),
            'CRAWLER_SYNC_DELAY_MIN': current_app.config.get('CRAWLER_SYNC_DELAY_MIN') or float(os.environ.get('CRAWLER_SYNC_DELAY_MIN', 0.3)),
            'CRAWLER_SYNC_DELAY_MAX': current_app.config.get('CRAWLER_SYNC_DELAY_MAX') or float(os.environ.get('CRAWLER_SYNC_DELAY_MAX', 0.8)),
            'HEARTBEAT_INTERVAL': current_app.config.get('HEARTBEAT_INTERVAL') or int(os.environ.get('HEARTBEAT_INTERVAL', 60)),
            'GLOBAL_ERROR_THRESHOLD': current_app.config.get('GLOBAL_ERROR_THRESHOLD') or int(os.environ.get('GLOBAL_ERROR_THRESHOLD', 300)),
            'AUTO_CRAWL_ENABLED': current_app.config.get('AUTO_CRAWL_ENABLED') or os.environ.get('AUTO_CRAWL_ENABLED') in ('true', '1', 'yes'),
            'AUTO_CRAWL_TIME': current_app.config.get('AUTO_CRAWL_TIME') or os.environ.get('AUTO_CRAWL_TIME') or '03:00',
            'CRAWL_FORUMS': [],
            'CRAWL_DATE_MODE': 'all',
            'CRAWL_PAGE_MODE': 'fixed',
            'CRAWL_MAX_PAGES': 3,
            'CRAWL_SMART_LIMIT': 500
        })
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        return response


@api_core_bp.route('/config/telegram-templates', methods=['GET'])
def api_telegram_templates_get():
    """è·å– Telegram é€šçŸ¥æ¨¡æ¿ï¼ˆåŸå§‹å†…å®¹ + ç»“æ„åŒ–é…ç½® + å ä½ç¬¦è¯´æ˜ï¼‰"""
    start_time = time.time()
    try:
        import scheduler.notifier as notifier

        def extract_placeholders(text: str) -> str:
            if not text:
                return ''
            start = text.find('å ä½ç¬¦è¯´æ˜')
            if start == -1:
                return ''
            end = text.find('TEMPLATES =', start)
            section = text[start:end] if end != -1 else text[start:]
            lines = []
            for line in section.splitlines():
                stripped = line.lstrip()
                if stripped.startswith('#'):
                    cleaned = stripped[1:]
                    if cleaned.startswith(' '):
                        cleaned = cleaned[1:]
                    lines.append(cleaned.rstrip())
                elif stripped.startswith('"""') or stripped.startswith("'''"):
                    continue
                else:
                    lines.append(line.rstrip())
            return "\n".join(lines).strip()

        path = notifier._resolve_templates_path()
        notifier._ensure_templates_file(path)

        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()

        templates = notifier.load_telegram_templates()
        placeholders = extract_placeholders(content)

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/config/telegram-templates',
            params={"path": path},
            status='success',
            response_code=200,
            duration_ms=(time.time() - start_time) * 1000
        )

        response, status = success_response(
            data={"content": content, "templates": templates, "placeholders": placeholders, "path": path},
            message='è·å–æ¨¡æ¿æˆåŠŸ'
        )
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        return response, status
    except Exception as e:
        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/config/telegram-templates'},
            message='è·å–æ¨¡æ¿å¤±è´¥'
        )
        log_api_call(
            logger,
            method='GET',
            endpoint='/api/config/telegram-templates',
            params={},
            status='error',
            response_code=500,
            duration_ms=(time.time() - start_time) * 1000,
            error=str(e)
        )
        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='è·å–æ¨¡æ¿å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/config/telegram-templates', methods=['POST'])
def api_telegram_templates_set():
    """ä¿å­˜æˆ–é‡ç½® Telegram é€šçŸ¥æ¨¡æ¿"""
    start_time = time.time()
    try:
        import scheduler.notifier as notifier

        def render_templates_py(path: str, templates: dict) -> str:
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    base = f.read()
            except Exception:
                base = notifier._build_default_templates_py()

            if 'TEMPLATES =' not in base:
                base = notifier._build_default_templates_py()

            prefix = base.split('TEMPLATES =', 1)[0]
            pretty = pprint.pformat(templates, width=120, sort_dicts=False)
            return f"{prefix}TEMPLATES = {pretty}\n"

        path = notifier._resolve_templates_path()
        notifier._ensure_templates_file(path)

        data = request.get_json(silent=True) or {}
        action = (data.get('action') or '').strip()

        if action == 'reset':
            if path.endswith('.py'):
                content = notifier._build_default_templates_py()
            else:
                content = json.dumps(notifier.DEFAULT_TEMPLATES, ensure_ascii=False, indent=2)

            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/config/telegram-templates',
                params={'action': 'reset'},
                status='success',
                response_code=200,
                duration_ms=(time.time() - start_time) * 1000
            )

            return success_response(
                data={"content": content},
                message='æ¨¡æ¿å·²æ¢å¤é»˜è®¤'
            )

        templates = data.get('templates')
        if isinstance(templates, dict):
            if path.endswith('.json'):
                content = json.dumps(templates, ensure_ascii=False, indent=2)
            else:
                content = render_templates_py(path, templates)

            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)

            log_api_call(
                logger,
                method='POST',
                endpoint='/api/config/telegram-templates',
                params={'action': 'save', 'mode': 'structured'},
                status='success',
                response_code=200,
                duration_ms=(time.time() - start_time) * 1000
            )

            return success_response(
                data={"content": content},
                message='æ¨¡æ¿å·²ä¿å­˜'
            )

        content = data.get('content')
        if not isinstance(content, str):
            return invalid_parameter_response('content', 'æ¨¡æ¿å†…å®¹å¿…é¡»æ˜¯å­—ç¬¦ä¸²')
        if not content.strip():
            return invalid_parameter_response('content', 'æ¨¡æ¿å†…å®¹ä¸èƒ½ä¸ºç©º')

        if path.endswith('.json'):
            try:
                parsed = json.loads(content)
                content = json.dumps(parsed, ensure_ascii=False, indent=2)
            except Exception:
                return invalid_parameter_response('content', 'JSON æ ¼å¼ä¸æ­£ç¡®')

        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/config/telegram-templates',
            params={'action': 'save', 'mode': 'raw'},
            status='success',
            response_code=200,
            duration_ms=(time.time() - start_time) * 1000
        )

        return success_response(
            data={"content": content},
            message='æ¨¡æ¿å·²ä¿å­˜'
        )

    except Exception as e:
        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/config/telegram-templates'},
            message='ä¿å­˜æ¨¡æ¿å¤±è´¥'
        )
        log_api_call(
            logger,
            method='POST',
            endpoint='/api/config/telegram-templates',
            params={},
            status='error',
            response_code=500,
            duration_ms=(time.time() - start_time) * 1000,
            error=str(e)
        )
        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='ä¿å­˜æ¨¡æ¿å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/config/test-telegram', methods=['POST'])
def api_test_telegram():
    """æµ‹è¯• Telegram Bot é…ç½®æ˜¯å¦æ­£ç¡®"""
    try:
        data = request.get_json() or {}

        # å¦‚æœå‰ç«¯æ²¡æœ‰ä¼ å…¥ï¼Œåˆ™ä»é…ç½®è¯»å–
        token = data.get('token', '').strip()
        chat_id = data.get('chat_id', '').strip()

        if not token or not chat_id:
            from configuration import config_manager
            if not token:
                token = config_manager.get('TG_BOT_TOKEN', '')
            if not chat_id:
                chat_id = config_manager.get('TG_NOTIFY_CHAT_ID', '')

        if not token:
            return jsonify({
                'status': 'error',
                'message': 'Bot Token æœªé…ç½®'
            }), 400

        if not chat_id:
            return jsonify({
                'status': 'error',
                'message': 'Chat ID æœªé…ç½®'
            }), 400

        # å°è¯•å‘é€æµ‹è¯•æ¶ˆæ¯
        import requests
        from datetime import datetime
        from utils.retry_utils import retry_request, RETRY_CONFIG

        test_message = f"ğŸ¤– Telegram Bot æµ‹è¯•æ¶ˆæ¯\n\nâœ… é…ç½®æ­£å¸¸ï¼\n\nğŸ• æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\næ¥è‡ª: SHT èµ„æºèšåˆç³»ç»Ÿ"

        url = f"https://api.telegram.org/bot{token}/sendMessage"
        payload = {
            'chat_id': chat_id,
            'text': test_message,
            'parse_mode': 'HTML'
        }

        # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œä½¿ç”¨ä»£ç†ï¼ˆå¦‚æœæœ‰é…ç½®ï¼‰
        proxy_url = config_manager.get('PROXY', '')
        proxies = {'http': proxy_url, 'https': proxy_url} if proxy_url else None

        config = RETRY_CONFIG['telegram']
        response = retry_request(
            requests.post,
            url=url,
            json=payload,
            proxies=proxies,
            raise_on_fail=False,
            **config
        )

        if response:
            try:
                result = response.json()
                if result.get('ok'):
                    logger.info(f"âœ“ [TELEGRAM] æµ‹è¯•æ¶ˆæ¯å‘é€æˆåŠŸ - Chat ID: {chat_id}")
                    return jsonify({
                        'status': 'success',
                        'message': 'æµ‹è¯•æ¶ˆæ¯å‘é€æˆåŠŸï¼è¯·æ£€æŸ¥æ‚¨çš„ Telegram'
                    })
                else:
                    error_msg = result.get('description', 'æœªçŸ¥é”™è¯¯')
                    logger.warning(f"âœ— [TELEGRAM] æµ‹è¯•æ¶ˆæ¯å‘é€å¤±è´¥: {error_msg}")
                    return jsonify({
                        'status': 'error',
                        'message': f'å‘é€å¤±è´¥: {error_msg}'
                    }), 400
            except Exception as e:
                logger.error(f"âœ— [TELEGRAM] è§£æå“åº”å¤±è´¥: {e}")
                return jsonify({
                    'status': 'error',
                    'message': f'è§£æå“åº”å¤±è´¥: {str(e)}'
                }), 500
        else:
            logger.error("âœ— [TELEGRAM] æµ‹è¯•æ¶ˆæ¯å‘é€å¤±è´¥ï¼ˆæ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼‰")
            return jsonify({
                'status': 'error',
                'message': 'å‘é€å¤±è´¥ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä»£ç†é…ç½®'
            }), 500

    except Exception as e:
        logger.error(f"âœ— [TELEGRAM] æµ‹è¯•å¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'æµ‹è¯•å¤±è´¥: {str(e)}'
        }), 500


# ==================== èµ„æºå’Œåˆ†ç±»API ====================

@api_core_bp.route('/resources')
def api_resources():
    """è·å–èµ„æºåˆ—è¡¨ï¼Œæ”¯æŒå¤šç§ç­›é€‰æ¡ä»¶"""
    start_time = time.time()

    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„å‚æ•°éªŒè¯å™¨
        page, per_page, error = RequestParams.get_pagination_params()
        if error:
            return error

        category, error = RequestParams.get_category_params()
        if error:
            return error

        search, error = RequestParams.get_search_params(min_length=2, max_length=200)
        if error:
            return error

        date_start, date_end, error = RequestParams.get_date_range_params()
        if error:
            return error

        incomplete_type = request.args.get('incomplete_type')

        logger.info(
            f'[API] èµ„æºç­›é€‰ - åˆ†ç±»: {category or "å…¨éƒ¨"}, '
            f'æœç´¢: {search or "æ— "}, '
            f'æ®‹ç¼º: {incomplete_type or "æ— "}, '
            f'æ—¥æœŸ: {date_start or "æ— "} åˆ° {date_end or "æ— "}, '
            f'é¡µç : {page}, æ¯é¡µ: {per_page}'
        )

        # ä½¿ç”¨ç»Ÿä¸€æœåŠ¡å±‚è·å–èµ„æº
        result_data = UnifiedService.resource_service.get_resources_with_filters(
            page=page,
            per_page=per_page,
            category=category,
            search=search,
            date_start=date_start,
            date_end=date_end,
            incomplete_type=incomplete_type
        )

        # æ„å»ºè¿”å›æ•°æ®
        response_data = {
            'resources': result_data['resources'],
            'total': result_data['total'],
            'pages': result_data['pages'],
            'current_page': result_data['current_page'],
            'per_page': result_data['per_page'],
            'has_next': result_data['has_next'],
            'has_prev': result_data['has_prev'],
            'filters': {
                'category': category,
                'search': search,
                'date_start': date_start,
                'date_end': date_end
            }
        }

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/resources',
            params={'page': page, 'per_page': per_page, 'category': category, 'search': search},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        return success_response(
            data=response_data,
            message=f'è·å–èµ„æºåˆ—è¡¨æˆåŠŸï¼Œå…± {result_data["total"]} æ¡è®°å½•'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/resources', 'params': request.args.to_dict()},
            message='ç­›é€‰èµ„æºå¤±è´¥'
        )

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/resources',
            params=request.args.to_dict(),
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message=f'ç­›é€‰èµ„æºå¤±è´¥: {str(e)}',
            details=str(e)
        )


@api_core_bp.route('/resources/batch-recycle', methods=['POST'])
def api_resources_batch_recycle():
    """æ‰¹é‡èµ„æºå›ç‚‰é‡é€  (æ”¯æŒæ‰‹åŠ¨é€‰æ‹©å’Œå…¨é‡åŒ¹é…ç­›é€‰)"""
    start_time = time.time()
    try:
        data = request.get_json() or {}
        tids = data.get('tids', [])
        all_matching = data.get('all_matching', False)
        
        from models import FailedTID, Resource
        recycled_count = 0
        
        target_resources = []
        
        if all_matching:
            # ç­–ç•¥ï¼šæ ¹æ®å½“å‰æ‰€æœ‰ç­›é€‰æ¡ä»¶ï¼Œæ‰¾å‡ºæ‰€æœ‰åŒ¹é…çš„èµ„æºï¼ˆä¸åˆ†é¡µï¼‰
            filters = data.get('filters', {})
            logger.info(f"[API] è§¦å‘å…¨é‡å›ç‚‰ï¼Œæ¡ä»¶: {filters}")
            
            # ä½¿ç”¨ç°æœ‰æœåŠ¡é€»è¾‘è·å–æŸ¥è¯¢å¯¹è±¡ï¼ˆç¨ä½œä¿®æ”¹ä»¥ä¸é™åˆ¶åˆ†é¡µï¼‰
            query = Resource.query
            
            # é‡å¤åº”ç”¨ç­›é€‰é€»è¾‘ (è¿™é‡Œä¸ºäº†é«˜æ€§èƒ½ï¼Œæˆ‘ä»¬ç›´æ¥æ“ä½œ query)
            if filters.get('category') and filters['category'] != 'all':
                query = query.filter(Resource.section == filters['category'])
            
            inc = filters.get('incomplete_type')
            if inc:
                types = inc.split(',')
                is_unknown_sub = (Resource.sub_type == 'æœªçŸ¥') | (Resource.sub_type == '') | (Resource.sub_type.is_(None))
                is_unknown_date = (Resource.publish_date == 'æœªçŸ¥') | (Resource.publish_date == '') | (Resource.publish_date.is_(None))
                is_unknown_size = (Resource.size == 0) | (Resource.size.is_(None))
                
                if 'sub_type_missing' in types: query = query.filter(is_unknown_sub)
                if 'date_missing' in types: query = query.filter(is_unknown_date)
                if 'size_missing' in types: query = query.filter(is_unknown_size)
                # ... (æ­¤å¤„é€»è¾‘ä¸ get_resources_with_filters ä¿æŒåŒæ­¥)

            if filters.get('search'):
                term = f"%{filters['search']}%"
                query = query.filter(or_(Resource.title.ilike(term), Resource.sub_type.ilike(term)))
                
            target_resources = query.all()
            logger.info(f"å…¨é‡å›ç‚‰æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(target_resources)} æ¡åŒ¹é…é¡¹")
        else:
            # æ‰‹åŠ¨é€‰æ‹©æ¨¡å¼
            if not tids:
                return invalid_parameter_response(message='è¯·æŒ‡å®šè¦å›ç‚‰çš„ TID åˆ—è¡¨')
            target_resources = Resource.query.filter(Resource.tid.in_(tids)).all()

        if not target_resources:
            return success_response(data={'recycled_count': 0}, message='æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„èµ„æº')

        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        for res in target_resources:
            # 1. åŠ å…¥é‡è¯•åˆ—è¡¨
            FailedTID.add(
                tid=res.tid,
                section=res.section,
                url=res.detail_url or f"https://sehuatang.org/forum.php?mod=viewthread&tid={res.tid}",
                reason="ç”¨æˆ·æ‰‹åŠ¨ç”³è¯·æ‰¹é‡é‡ä¿®",
                force_activate=True  # æ ¸å¿ƒç‚¹ï¼šå¼ºåˆ¶æ¿€æ´»ï¼Œæ— è§†ä¹‹å‰çš„â€œæˆåŠŸâ€çŠ¶æ€
            )
            # 2. ä»ä¸»è¡¨ç§»é™¤
            db.session.delete(res)
            recycled_count += 1
        
        db.session.commit()
        
        duration_ms = (time.time() - start_time) * 1000
        logger.info(f'[API] æ‰¹é‡èµ„æºå›ç‚‰ - æˆåŠŸ: {recycled_count} æ¡')
        
        return success_response(
            data={'recycled_count': recycled_count},
            message=f'å·²æˆåŠŸå°† {recycled_count} æ¡èµ„æºé€å›é‡é€ é˜Ÿåˆ—'
        )
        
    except Exception as e:
        db.session.rollback()
        log_error_with_traceback(logger, e, message='æ‰¹é‡å›ç‚‰æ“ä½œå¤±è´¥')
        return error_response(code=ErrorCode.INTERNAL_ERROR, message='æ‰¹é‡å›ç‚‰æ“ä½œå¤±è´¥')


@api_core_bp.route('/categories')
def api_categories():
    """è·å–æ‰€æœ‰åˆ†ç±»ï¼ŒåŒ…æ‹¬æ•°æ®åº“ä¸­çš„å®é™…åˆ†ç±»å’Œç»Ÿè®¡ä¿¡æ¯ - æ·»åŠ ç¼“å­˜ä¼˜åŒ–"""
    start_time = time.time()

    # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå»¶é•¿ç¼“å­˜æ—¶é—´åˆ°15åˆ†é’Ÿï¼‰
    cache_key = CacheKeys.CATEGORIES
    cached_categories = cache_manager.get(cache_key)
    if cached_categories:
        return jsonify(cached_categories)

    try:
        # è·å–æ•°æ®åº“ä¸­å®é™…å­˜åœ¨çš„åˆ†ç±»ï¼ˆä»Resourceè¡¨ï¼‰
        existing_categories = db.session.query(
            Resource.section,
            func.count(Resource.id).label('count')
        ).filter(
            Resource.section.isnot(None),
            Resource.section != ''
        ).group_by(Resource.section).all()

        # è·å–Categoryè¡¨ä¸­å®šä¹‰çš„æ‰€æœ‰åˆ†ç±»
        defined_categories = Category.query.all()
        defined_cat_dict = {cat.name: cat for cat in defined_categories}

        # æ„å»ºåˆ†ç±»åˆ—è¡¨ï¼ŒåŒ…å«ç»Ÿè®¡ä¿¡æ¯
        categories_list = []

        # æ·»åŠ æ•°æ®åº“ä¸­å®é™…å­˜åœ¨çš„åˆ†ç±»
        for section_name, count in existing_categories:
            cat_info = {
                'name': section_name,
                'count': count,
                'defined': section_name in defined_cat_dict
            }
            # å¦‚æœåœ¨Categoryè¡¨ä¸­æœ‰å®šä¹‰ï¼Œæ·»åŠ è¿œç¨‹ä¸»é¢˜å’Œé¡µæ•°ä¿¡æ¯
            if section_name in defined_cat_dict:
                cat_obj = defined_cat_dict[section_name]
                cat_info['total_topics'] = cat_obj.total_topics or 0
                cat_info['total_pages'] = cat_obj.total_pages or 0
                cat_info['fid'] = cat_obj.fid
            categories_list.append(cat_info)

        # æ·»åŠ å®šä¹‰ä½†å¯èƒ½æ²¡æœ‰æ•°æ®çš„åˆ†ç±»
        for cat in defined_categories:
            if cat.name not in [c['name'] for c in categories_list]:
                categories_list.append({
                    'name': cat.name,
                    'count': 0,
                    'defined': True,
                    'total_topics': cat.total_topics or 0,
                    'total_pages': cat.total_pages or 0,
                    'fid': cat.fid
                })

        # æŒ‰åç§°æ’åº
        categories_list.sort(key=lambda x: x['name'])

        # ç¼“å­˜ç»“æœï¼ˆ72å°æ—¶ = 259200ç§’ï¼‰
        cache_manager.set(cache_key, categories_list, ttl=259200)

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/categories',
            params={},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        return jsonify(categories_list)

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/categories'},
            message='è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥'
        )

        # è¿”å›åŸºç¡€åˆ†ç±»åˆ—è¡¨ä½œä¸ºå¤‡é€‰
        try:
            categories = Category.query.all()
            fallback_list = [{'name': c.name, 'count': 0, 'defined': True} for c in categories]

            log_api_call(
                logger,
                method='GET',
                endpoint='/api/categories',
                params={'note': 'fallback used'},
                status='success',
                response_code=200,
                duration_ms=duration_ms
            )

            return jsonify(fallback_list)
        except Exception as fallback_err:
            log_api_call(
                logger,
                method='GET',
                endpoint='/api/categories',
                params={'note': 'fallback failed'},
                status='error',
                response_code=500,
                duration_ms=duration_ms,
                error=str(fallback_err)
            )

            return jsonify([])


@api_core_bp.route('/stats/categories')
def api_stats_categories():
    """æŒ‰åˆ†ç±»ç»Ÿè®¡æ¡ç›®æ•°"""
    start_time = time.time()

    try:
        logger.info(f"[STATS] å¼€å§‹è·å–åˆ†ç±»ç»Ÿè®¡æ•°æ®")

        # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        force_refresh = request.args.get('force', 'false').lower() == 'true'

        if not force_refresh:
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = cache_manager.get(CacheKeys.CATEGORIES)
            if cached_result:
                logger.info(f"âœ“ [CACHE] ä»ç¼“å­˜è¿”å›åˆ†ç±»ç»Ÿè®¡æ•°æ®: {len(cached_result)}ä¸ªåˆ†ç±»")

                duration_ms = (time.time() - start_time) * 1000

                log_api_call(
                    logger,
                    method='GET',
                    endpoint='/api/stats/categories',
                    params={'force': force_refresh, 'note': 'from cache'},
                    status='success',
                    response_code=200,
                    duration_ms=duration_ms
                )

                return success_response(
                    data=cached_result,
                    message=f'ä»ç¼“å­˜è·å–åˆ†ç±»ç»Ÿè®¡ï¼Œå…± {len(cached_result)} ä¸ªåˆ†ç±»'
                )

        # ä½¿ç”¨ç»Ÿä¸€æœåŠ¡å±‚è·å–åˆ†ç±»æ•°æ®
        try:
            categories_list = UnifiedService.category_service.get_all_categories(
                include_stats=True,
                include_defined=False
            )
        except Exception as service_error:
            logger.error(f"[STATS] æœåŠ¡å±‚è·å–åˆ†ç±»å¤±è´¥: {service_error}")
            # é™çº§æ–¹æ¡ˆï¼šç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢
            existing_categories = db.session.query(
                Resource.section,
                func.count(Resource.id).label('count')
            ).filter(
                Resource.section.isnot(None),
                Resource.section != ''
            ).group_by(Resource.section).all()

            categories_list = []
            for section_name, count in existing_categories:
                categories_list.append({
                    'name': section_name,
                    'count': count
                })

        # æå–ç»Ÿè®¡æ•°æ®
        result = []
        if isinstance(categories_list, dict):
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
            result = [
                {'section': cat.get('name', 'æœªçŸ¥'), 'count': cat.get('count', 0)}
                for cat in categories_list.values()
            ]
        elif isinstance(categories_list, list):
            result = [
                {'section': cat.get('name', 'æœªçŸ¥'), 'count': cat.get('count', 0)}
                for cat in categories_list
            ]
        else:
            result = categories_list

        logger.info(f"âœ“ [STATS] ç»Ÿè®¡APIè¿”å›: {len(result)}ä¸ªåˆ†ç±»")
        for item in result[:5]:
            logger.info(f"  - {item['section']}: {item['count']} æ¡")

        # ç¼“å­˜ç»“æœï¼ˆ5åˆ†é’Ÿï¼‰
        cache_manager.set(CacheKeys.CATEGORIES, categories_list, ttl=300)

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/stats/categories',
            params={'force': force_refresh},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        return success_response(
            data=result,
            message=f'è·å–åˆ†ç±»ç»Ÿè®¡æˆåŠŸï¼Œå…± {len(result)} ä¸ªåˆ†ç±»'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/stats/categories', 'params': request.args.to_dict()},
            message='è·å–åˆ†ç±»ç»Ÿè®¡å¤±è´¥'
        )

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/stats/categories',
            params=request.args.to_dict(),
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='è·å–åˆ†ç±»ç»Ÿè®¡å¤±è´¥',
            details=str(e)
        )


# ==================== æ—¥å¿—API ====================

@api_core_bp.route('/logs/test')
def api_logs_test():
    """æµ‹è¯•æ—¥å¿—API - ç”¨äºè¯Šæ–­"""
    LOG_FILE = current_app.config.get('LOG_FILE', '')
    
    return jsonify({
        'log_file_path': LOG_FILE,
        'file_exists': os.path.exists(LOG_FILE) if LOG_FILE else False,
        'config_log_file': LOG_FILE
    })


@api_core_bp.route('/logs/recent')
def api_logs_recent():
    """è·å–æœ€è¿‘çš„æ—¥å¿—"""
    start_time = time.time()
    global _log_version

    LOG_FILE = current_app.config.get('LOG_FILE', '')
    limit = request.args.get('limit', 300, type=int)

    # åº”ç”¨å‚æ•°éªŒè¯
    if limit < 1:
        limit = 1
    elif limit > 10000:
        limit = 10000

    lines = []

    # ä¼˜å…ˆä»æ–‡ä»¶è¯»å–ï¼ˆå¤šworkerå…±äº«ï¼‰
    try:
        if LOG_FILE and os.path.exists(LOG_FILE):
            with open(LOG_FILE, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.splitlines()[-limit:]
    except Exception as e:
        logger.error(f"[LOGS] è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        pass

    # é€€å›å†…å­˜ç¼“å†²
    if not lines:
        lines = list(logs_buffer)[-limit:]
        logger.info(f"[LOGS] ä»å†…å­˜ç¼“å†²è¯»å–: {len(lines)} è¡Œ")

    duration_ms = (time.time() - start_time) * 1000

    log_api_call(
        logger,
        method='GET',
        endpoint='/api/logs/recent',
        params={'limit': limit},
        status='success',
        response_code=200,
        duration_ms=duration_ms
    )

    # ç›´æ¥è¿”å›å‰ç«¯æœŸæœ›çš„æ ¼å¼
    return jsonify({
        'lines': lines,
        'version': _log_version,
        'timestamp': datetime.now().isoformat()
    })


@api_core_bp.route('/logs/search')
def api_logs_search():
    """æœç´¢æ—¥å¿—"""
    start_time = time.time()

    try:
        LOG_FILE = current_app.config.get('LOG_FILE', '')
        q = (request.args.get('q') or '').strip()
        limit = request.args.get('limit', 300, type=int)

        lines = []
        try:
            if LOG_FILE and os.path.exists(LOG_FILE):
                with open(LOG_FILE, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    lines = content.splitlines()
        except Exception:
            pass

        if not lines:
            lines = list(logs_buffer)

        if q:
            ql = q.lower()
            lines = [ln for ln in lines if ql in ln.lower()]

        lines = lines[-limit:]

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/logs/search',
            params={'q': q, 'limit': limit},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        return success_response(
            data={'lines': lines, 'count': len(lines)},
            message=f'æœç´¢æ—¥å¿—æˆåŠŸï¼Œæ‰¾åˆ° {len(lines)} æ¡è®°å½•'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/logs/search', 'params': request.args.to_dict()},
            message='æœç´¢æ—¥å¿—å¤±è´¥'
        )

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/logs/search',
            params=request.args.to_dict(),
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='æœç´¢æ—¥å¿—å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/logs/session')
def api_logs_session():
    """è·å–æœ¬æ¬¡å¯åŠ¨æœŸé—´çš„æ—¥å¿—"""
    start_time = time.time()

    LOG_FILE = current_app.config.get('LOG_FILE', '')
    limit = request.args.get('limit', 1000, type=int)

    # åº”ç”¨å‚æ•°éªŒè¯
    if limit < 1:
        limit = 1
    elif limit > 10000:
        limit = 10000

    lines = []
    session_lines = []

    try:
        if LOG_FILE and os.path.exists(LOG_FILE):
            with open(LOG_FILE, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.splitlines()
    except Exception:
        pass

    if not lines:
        lines = list(logs_buffer)

    # å°è¯•æ ¹æ®æ—¶é—´æˆ³ç­›é€‰æœ¬æ¬¡å¯åŠ¨çš„æ—¥å¿—
    for line in lines:
        # ç®€å•çš„å¯åŠ¨æ ‡è¯†æ£€æŸ¥
        if any(keyword in line for keyword in [
            'SHTèµ„æºèšåˆç³»ç»Ÿå¯åŠ¨æˆåŠŸ',
            'å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“',
            'é…ç½®éªŒè¯é€šè¿‡',
            'Flaskåº”ç”¨å¯åŠ¨'
        ]):
            # æ‰¾åˆ°å¯åŠ¨æ ‡è¯†åï¼Œä»è¿™é‡Œå¼€å§‹æ”¶é›†æ—¥å¿—
            session_lines = []
        session_lines.append(line)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯åŠ¨æ ‡è¯†ï¼Œè¿”å›æœ€è¿‘çš„æ—¥å¿—
    if not session_lines:
        session_lines = lines[-limit:]
    else:
        session_lines = session_lines[-limit:]

    duration_ms = (time.time() - start_time) * 1000

    log_api_call(
        logger,
        method='GET',
        endpoint='/api/logs/session',
        params={'limit': limit},
        status='success',
        response_code=200,
        duration_ms=duration_ms
    )

    return success_response(
        data={
            'lines': session_lines,
            'total': len(session_lines),
            'message': f'æœ¬æ¬¡å¯åŠ¨æœŸé—´çš„æ—¥å¿— (å…± {len(session_lines)} æ¡)'
        },
        message=f'è·å–ä¼šè¯æ—¥å¿—æˆåŠŸï¼Œå…± {len(session_lines)} æ¡'
    )


@api_core_bp.route('/logs/export')
def api_logs_export():
    """å¯¼å‡ºæ—¥å¿—æ–‡ä»¶"""
    start_time = time.time()
    LOG_FILE = current_app.config.get('LOG_FILE', '')
    try:
        # åˆ›å»ºæ—¶é—´æˆ³
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # æ”¶é›†æ‰€æœ‰æ—¥å¿—å†…å®¹
        all_logs = []

        # ä»æ–‡ä»¶è¯»å–
        if LOG_FILE and os.path.exists(LOG_FILE):
            try:
                with open(LOG_FILE, 'r', encoding='utf-8', errors='ignore') as f:
                    all_logs.extend(f.readlines())
            except Exception as e:
                all_logs.append(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}\n")

        # ä»å†…å­˜ç¼“å†²è¯»å–
        if logs_buffer:
            all_logs.extend([line + '\n' for line in logs_buffer])

        if not all_logs:
            all_logs = ['æš‚æ— æ—¥å¿—æ•°æ®\n']

        # åˆ›å»ºå“åº”å†…å®¹
        log_content = ''.join(all_logs)

        # è¿”å›æ–‡ä»¶ä¸‹è½½
        response = Response(
            log_content,
            mimetype='text/plain',
            headers={
                'Content-Disposition': f'attachment; filename=sht_logs_{timestamp}.txt',
                'Content-Type': 'text/plain; charset=utf-8'
            }
        )

        return response

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/logs/export'},
            message='å¯¼å‡ºæ—¥å¿—å¤±è´¥'
        )

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/logs/export',
            params={},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='å¯¼å‡ºæ—¥å¿—å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/logs/clear', methods=['POST'])
def api_logs_clear():
    """æ¸…é™¤æ—¥å¿—ç¼“å­˜API"""
    global _log_version

    LOG_FILE = current_app.config.get('LOG_FILE', '')

    try:
        # æ¸…é™¤å†…å­˜ç¼“å†²åŒº
        if logs_buffer is not None:
            logs_buffer.clear()
        else:
            logger.warning("ğŸ§ª [CLEAN] logs_buffer ä¸º Noneï¼Œè·³è¿‡å†…å­˜æ¸…ç†")

        # åŒæ—¶æ¸…é™¤æ—¥å¿—æ–‡ä»¶å†…å®¹
        if LOG_FILE and os.path.exists(LOG_FILE):
            with open(LOG_FILE, 'w', encoding='utf-8') as f:
                f.truncate(0)

        # é€’å¢ç‰ˆæœ¬å·ï¼Œå¼ºåˆ¶å‰ç«¯åˆ·æ–°
        _log_version += 1

        logger.info(f"âœ“ [CLEAN] æ—¥å¿—ç¼“å­˜å·²æ¸…é™¤ï¼ˆåŒ…æ‹¬æ–‡ä»¶ï¼‰ï¼Œç‰ˆæœ¬å·: {_log_version}")

        return jsonify({
            'status': 'success',
            'message': 'æ—¥å¿—ç¼“å­˜å·²æ¸…é™¤',
            'version': _log_version,
            'timestamp': datetime.now(timezone.utc).isoformat()
        })

    except Exception as e:
        logger.error(f"âœ— [CLEAN] æ¸…é™¤æ—¥å¿—ç¼“å­˜å¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }), 500


# ==================== ç»´æŠ¤API ====================

@api_core_bp.route('/maintenance/cleanup', methods=['POST'])
def api_maintenance_cleanup():
    """æ•°æ®ç»´æŠ¤æ¸…ç†API"""
    start_time = time.time()

    try:
        from maintenance_tools import DatabaseMaintenance

        maintenance = DatabaseMaintenance()

        # è·å–æ¸…ç†ç±»å‹
        data = request.get_json() or {}
        cleanup_type = data.get('type', 'duplicates')

        if not cleanup_type:
            duration_ms = (time.time() - start_time) * 1000
            return missing_parameter_response('type')

        result = {}

        if cleanup_type == 'duplicates':
            # æ¸…ç†é‡å¤æ•°æ®
            removed_count = Resource.cleanup_duplicates()
            result = {
                'type': 'duplicates',
                'removed_count': removed_count,
                'message': f'æ¸…ç†äº† {removed_count} æ¡é‡å¤è®°å½•'
            }
        elif cleanup_type == 'normalize_dates':
            # æ ‡å‡†åŒ–æ—¥æœŸ
            with current_app.app_context():
                maintenance.normalize_dates()
            result = {
                'type': 'normalize_dates',
                'normalized_count': maintenance.stats.get('normalized_dates', 0),
                'message': f'æ ‡å‡†åŒ–äº† {maintenance.stats.get("normalized_dates", 0)} æ¡æ—¥æœŸè®°å½•'
            }
        elif cleanup_type == 'optimize':
            # ä¼˜åŒ–æ•°æ®åº“
            with current_app.app_context():
                maintenance.optimize_database()
            result = {
                'type': 'optimize',
                'message': 'æ•°æ®åº“ä¼˜åŒ–å®Œæˆ'
            }
        elif cleanup_type == 'full':
            # å®Œæ•´ç»´æŠ¤
            maintenance.run_full_maintenance()
            result = {
                'type': 'full',
                'stats': maintenance.stats,
                'message': 'å®Œæ•´ç»´æŠ¤å®Œæˆ'
            }
        else:
            duration_ms = (time.time() - start_time) * 1000
            return invalid_parameter_response('type', details=f'ä¸æ”¯æŒçš„æ¸…ç†ç±»å‹: {cleanup_type}')

        # æ¸…ç†ç¼“å­˜
        cache_manager.clear()

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/maintenance/cleanup',
            params={'type': cleanup_type},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        return success_response(
            data=result,
            message='æ•°æ®ç»´æŠ¤å®Œæˆ'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/maintenance/cleanup'},
            message='æ•°æ®ç»´æŠ¤å¤±è´¥'
        )

        log_api_call(
            logger,
            method='POST',
            endpoint='/api/maintenance/cleanup',
            params={'type': request.get_json().get('type') if request.is_json else None},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='æ•°æ®ç»´æŠ¤å¤±è´¥',
            details=str(e)
        )


@api_core_bp.route('/maintenance/info')
def api_maintenance_info():
    """è·å–æ•°æ®åº“ç»´æŠ¤ä¿¡æ¯"""
    start_time = time.time()

    try:
        from maintenance_tools import DatabaseMaintenance

        maintenance = DatabaseMaintenance()
        info = maintenance.get_database_info()

        duration_ms = (time.time() - start_time) * 1000

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/maintenance/info',
            params={},
            status='success',
            response_code=200,
            duration_ms=duration_ms
        )

        return success_response(
            data=info,
            message='è·å–ç»´æŠ¤ä¿¡æ¯æˆåŠŸ'
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000

        log_error_with_traceback(
            logger,
            e,
            context={'endpoint': '/api/maintenance/info'},
            message='è·å–ç»´æŠ¤ä¿¡æ¯å¤±è´¥'
        )

        log_api_call(
            logger,
            method='GET',
            endpoint='/api/maintenance/info',
            params={},
            status='error',
            response_code=500,
            duration_ms=duration_ms,
            error=str(e)
        )

        return error_response(
            code=ErrorCode.INTERNAL_ERROR,
            message='è·å–ç»´æŠ¤ä¿¡æ¯å¤±è´¥',
            details=str(e)
        )
